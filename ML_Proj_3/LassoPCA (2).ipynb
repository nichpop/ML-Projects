{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4066fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = pd.read_csv('/Users/nick/Desktop/imputed_data.csv')\n",
    "\n",
    "# Select subset of independent variables\n",
    "pass_cols = ['passyds20','passtd20','passint20','passyds19','passtd19','passint19']  \n",
    "rush_cols = ['rushyds20','rushyds19','rushtd20','rush1st20', 'rushtd19','rush1st19']\n",
    "rec_cols = ['recyds20', 'rectd20', 'rec1st20', 'recyds19', 'rectd19', 'rec1st19']\n",
    "subset1_data = data[pass_cols]\n",
    "subset2_data = data[rush_cols]\n",
    "subset3_data = data[rec_cols]\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "scaler = StandardScaler()\n",
    "subset1_scaled = scaler.fit_transform(subset1_data)\n",
    "subset2_scaled = scaler.fit_transform(subset2_data)\n",
    "subset3_scaled = scaler.fit_transform(subset3_data)\n",
    "\n",
    "# PCA on the subset\n",
    "num_components = 3 \n",
    "pca = PCA(n_components=num_components)\n",
    "subset1_pca = pca.fit_transform(subset1_scaled)\n",
    "subset2_pca = pca.fit_transform(subset2_scaled)\n",
    "subset3_pca = pca.fit_transform(subset3_scaled)\n",
    "\n",
    "data['pass_latent'] = subset1_pca[:, 0]\n",
    "data['rush_latent'] = subset2_pca[:, 0]\n",
    "data['rec_latent'] = subset3_pca[:, 0]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "df = pd.read_csv('/Users/nick/Desktop/imputed_data.csv')\n",
    "\n",
    "df['pass_latent'] = subset1_pca[:, 0]\n",
    "df['rush_latent'] = subset2_pca[:, 0]\n",
    "df['rec_latent'] = subset3_pca[:, 0]\n",
    "\n",
    "bad_cols = ['gp_21', 'points21', 'projected22','actual19', 'actual21', 'passyd_21', 'passtds21', 'int21', 'runyds21', 'runtds21', 'run1st21', 'rec21', 'recyds21', 'rectds21', 'pass1st21', 'returnyds21', 'returntds21', 'twopoint21', 'fumble21']\n",
    "pass_cols = ['passyds20','passtd20','passint20','passyds19','passtd19','passint19']  \n",
    "rush_cols = ['rushyds20','rushyds19','rushtd20','rush1st20', 'rushtd19','rush1st19']\n",
    "rec_cols = ['recyds20', 'rectd20', 'rec1st20', 'recyds19', 'rectd19', 'rec1st19']\n",
    "\n",
    "# Split the dataset into IV and target Y (gini)\n",
    "X = df.drop(columns = bad_cols + pass_cols + rush_cols + rec_cols)\n",
    "y = df['points21']\n",
    "\n",
    "# Impute missing values with knn\n",
    "#imputer = KNNImputer(n_neighbors=10)\n",
    "#X_imputed = imputer.fit_transform(X)\n",
    "# drop na\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "# standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# set up k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# define a range of alpha values and max_iter values to try\n",
    "alphas = [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "max_iters = [100, 500, 1000, 5000, 10000]\n",
    "\n",
    "#store results for each alpha and max_iter combination\n",
    "results = {}\n",
    "\n",
    "#store coefficients for each alpha and max_iter combination\n",
    "coefficients_mapping = {}\n",
    "\n",
    "#store selected features for each alpha and max_iter combination\n",
    "selected_features_mapping = {}\n",
    "\n",
    "#store R-squared values for each alpha and max_iter combination\n",
    "r_squared_mapping = {}\n",
    "\n",
    "#feature selection based on coefficient magnitude max threshold\n",
    "coeff_threshold = 0.01  # Adjust as needed\n",
    "\n",
    "#top features to select\n",
    "top_n_features = 4  # Adjust as needed\n",
    "\n",
    "#i get a lot of warnings when I run the code so this hides them\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# iterate through different alpha values and max_iter values\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        mse_scores = []\n",
    "        r_squared_scores = []\n",
    "\n",
    "        #k-fold cross-validation\n",
    "        for train_index, test_index in kf.split(X_scaled):\n",
    "            X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            #lasso regression model\n",
    "            lasso_model = Lasso(alpha=alpha, max_iter=max_iter)\n",
    "\n",
    "            #fit the model on the training data\n",
    "            lasso_model.fit(X_train, y_train)\n",
    "\n",
    "            #make predictions on the test set\n",
    "            y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "            #eval the model\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse_scores.append(mse)\n",
    "\n",
    "            #calc R-squared\n",
    "            r_squared = r2_score(y_test, y_pred)\n",
    "            r_squared_scores.append(r_squared)\n",
    "\n",
    "        #average mse and R-squared across folds\n",
    "        avg_mse = np.mean(mse_scores)\n",
    "        avg_r_squared = np.mean(r_squared_scores)\n",
    "\n",
    "        #store the results for this alpha and max_iter combination\n",
    "        results[(alpha, max_iter)] = avg_mse\n",
    "        r_squared_mapping[(alpha, max_iter)] = avg_r_squared\n",
    "\n",
    "        #store the coefficients for this alpha and max_iter combination\n",
    "        coefficients_mapping[(alpha, max_iter)] = dict(zip(X.columns, lasso_model.coef_))\n",
    "\n",
    "        #features based on coefficient magnitude\n",
    "        selected_features = [feature for feature, coefficient in sorted(zip(X.columns, lasso_model.coef_), key=lambda x: abs(x[1]), reverse=True)[:top_n_features]]\n",
    "        selected_features_mapping[(alpha, max_iter)] = selected_features\n",
    "\n",
    "# find the alpha and max_iter with the lowest average mean squared error\n",
    "best_params = min(results, key=results.get)\n",
    "best_alpha, best_max_iter = best_params\n",
    "best_mse = results[best_params]\n",
    "best_r_squared = r_squared_mapping[best_params]\n",
    "\n",
    "# show the best alpha, max_iter, and their corresponding mean squared error and R-squared\n",
    "print(f'Best Alpha: {best_alpha}')\n",
    "print(f'Best Max Iterations: {best_max_iter}')\n",
    "print(f'Corresponding Mean Squared Error: {best_mse}')\n",
    "print(f'Corresponding R-squared: {best_r_squared}')\n",
    "\n",
    "# print coefficients for the best alpha and max_iter\n",
    "best_coefficients = coefficients_mapping[best_params]\n",
    "print(\"\\nCoefficients for the Best Alpha and Max Iterations:\")\n",
    "for feature, coefficient in best_coefficients.items():\n",
    "    print(f'{feature}: {coefficient}')\n",
    "\n",
    "# print selected features for the best alpha and max_iter\n",
    "selected_features = selected_features_mapping[best_params]\n",
    "print(\"\\nSelected Features for the Best Alpha and Max Iterations:\")\n",
    "print(selected_features)\n",
    "\n",
    "# show the coefficients using the best alpha and max_iter\n",
    "lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "lasso_model.fit(X_scaled, y)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(lasso_model.coef_)), lasso_model.coef_, marker='o', linestyle='None')\n",
    "plt.title('Lasso Coefficients with Best Alpha and Max Iterations')\n",
    "plt.xlabel('Coefficient Index')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba028137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
